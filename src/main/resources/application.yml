#application.properties
# Local Elasticsearch config
spring:
  application:
    name: es-kafka
  data:
    elasticsearch:
      cluster-name: elasticsearch
      cluster-nodes: localhost:9300
      repositories:
        enabled: true
  kafka:
    bootstrap-servers: 192.168.25.128:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 指定消息key和消息体的编解码方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: 1
      retries: 0
      batch-size: 16384 #每当多个记录被发送到同一分区时，生产者将尝试将记录一起批量处理为更少的请求，此配置控制默认批量大小（以字节为单位），默认值为16384
      buffer-memory: 33554432 #生产者可用于缓冲等待发送到服务器的记录的内存总字节数，默认值为33554432
    consumer:
      group-id: test-group
      enable-auto-commit: true #如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000
      auto-commit-interval: 1000
      max-poll-records: 1000 # 批量一次最大拉取数据量
      auto-offset-reset: earliest # 最早未被消费的offset
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer


  #spring:
  #    kafka:
  #        bootstrap-servers: 192.168.1.117:9092
  #        producer:
  #            # 重试次数
  #            retries: 3
  #            # 批量发送的消息数量
  #            batch-size: 16384
  #            # 32MB的批处理缓冲区
  #            buffer-memory: 33554432
  #        consumer:
  #            # 默认消费者组
  #            group-id: etl
  #            # 最早未被消费的offset
  #            auto-offset-reset: earliest
  #            # 批量一次最大拉取数据量
  #            max-poll-records: 1000
  #            # 自动提交
  #            auto-commit-interval: 1000
  #            enable-auto-commit: true
server:
  port: 8888

elasticsearch:
  index:
    name: my_index
  user:
    type: user
#logging:
#  level:
#    root: debug

topicName:
  topic1: test_topic1
  topic2: test_topic2
